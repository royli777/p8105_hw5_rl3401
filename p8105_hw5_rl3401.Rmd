---
title: "p8105_hw5_rl3401"
author: "Ruoxi Li"
date: "`r Sys.Date()`"
output: github_document
---

```{r}
library(tidyverse)
```

```{r}
homicides_df = read_csv("data/homicide-data.csv") 
head(homicides_df)

```

```{r}
homicide_summary=
  homicides_df |> 
  mutate(city_state = paste(city, state, sep = ", ")) |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(disposition %in% c("Closed without arrest", "Open/No arrest"))
  )

homicide_summary|>
  knitr::kable()
```

```{r}
baltimore_df =
  homicide_summary|>
  filter(city_state == "Baltimore, MD")

baltimore_prop_test =
  prop.test(baltimore_df$unsolved_homicides,baltimore_df$total_homicides)


baltimore_prop_test |>
  broom::tidy()|>
  select(estimate, conf.low, conf.high)|>
  knitr::kable()
```

```{r}
library(tidyverse)
perform_prop_test <- function(unsolved, total) {
  prop_test_result <- prop.test(unsolved, total)
  tidy_result <- broom::tidy(prop_test_result)
  return(tidy_result)
}

# Step 2: Apply the function to each city
all_cities_prop_test = homicide_summary |>
  mutate(prop_test_results = map2(unsolved_homicides, total_homicides, ~perform_prop_test(.x, .y))) |>
  unnest(prop_test_results) |>
  select(city_state, estimate, conf.low, conf.high)

all_cities_prop_test|>
   knitr::kable()
```

```{r}
ggplot(all_cities_prop_test, aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.2) +
  coord_flip() +
  labs(title = "Estimated Proportion of Unsolved Homicides by City",
       x = "City",
       y = "Proportion of Unsolved Homicides")
```


## Problem 2

```{r,message=FALSE}
full_df=
  tibble(path = list.files("data/hw5_data",full.names = TRUE))|>
  mutate(data = map(path, read_csv))
```

```{r}
tidy_df = 
  full_df |>
  unnest()|>
  mutate(
    arm = str_sub(path,15, 17),
    subject_id=str_sub(path, 19, 20)) |>
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    values_to = "outcome",
    names_prefix = "week_") |>
  mutate(week = as.numeric(week)) |>
  select(arm, subject_id , week, outcome)
```

```{r}
ggplot(tidy_df, aes(x = week, y = outcome, group = subject_id,color=subject_id))+
  geom_line()+
  labs(title = "Spaghetti Plot of Observations Over Time",
       x = "Time",
       y = "Outcome",
       color = "Subject_id") +
  theme_minimal()+
   facet_grid(~arm) 
```

## Problem 3

Set parameters:
```{r}
n <- 30
sigma <- 5
mu_values <- 0:6
alpha <- 0.05
num_simulations <- 5000
```

Create a dataframe to store results
```{r}
results <- data.frame(mu = numeric(), power = numeric())
```

Perform t-test
```{r}
for (mu in mu_values) {
  rejection_count <- 0
  for (i in 1:num_simulations) {
    sample_data <- rnorm(n, mean = mu, sd = sigma)
    test_result <- broom::tidy(t.test(sample_data, mu = 0))
    if (test_result$p.value < alpha) {
      rejection_count <- rejection_count + 1
    }
  }
  power <- rejection_count / num_simulations
  results <- rbind(results, data.frame(mu, power))
}
```

Plot showing the power of the test
```{r}
plot(results$mu, results$power, type = 'b', xlab = "True Value of Î¼", ylab = "Power of the Test",
     main = "Power vs Effect Size in One-Sample t-Test")

```
Power increases as the effect size increases.

Plot showing the average estimates of mu
```{r}
ggplot(results, aes(x = mu, y = mu_hat)) +
  geom_point(stat = "summary", fun = mean, color = "blue") +
  geom_point(data = subset(results, reject_null), aes(x = mu, y = mu_hat), stat = "summary", fun = mean, color = "red") +
  ylab("Average estimate of mu") +
  xlab("True value of mu")
```

When the mean is modest, particularly below 4 in this scenario, the observed discrepancy between the sample average \( \hat{\mu} \) in instances where the null hypothesis is rejected and the true mean becomes evident. This divergence can be attributed to the relatively minimal effect size coupled with a correspondingly lower statistical power of the test.
```
